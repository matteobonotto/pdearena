{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd()+'/..')\n",
    "\n",
    "from pdearena import utils\n",
    "import torch\n",
    "from pdearena.data.datamodule import PDEDataModule\n",
    "from pdearena.lr_scheduler import LinearWarmupCosineAnnealingLR  # noqa: F401\n",
    "from pdearena.models.pdemodel import PDEModel\n",
    "\n",
    "from helper_functions.data import write_h5, read_h5_numpy\n",
    "from helper_functions.general import touch_dir\n",
    "from time import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import _pickle as cPickle\n",
    "import pickle \n",
    "import hdf5plugin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/c/Users/eid0112947/OneDrive - Eni/Documenti/RESEARCH/pdearena/pdedatagen',\n",
       " '/home/bonotto/workspace/miniconda3/envs/pdearena/lib/python38.zip',\n",
       " '/home/bonotto/workspace/miniconda3/envs/pdearena/lib/python3.8',\n",
       " '/home/bonotto/workspace/miniconda3/envs/pdearena/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/home/bonotto/workspace/miniconda3/envs/pdearena/lib/python3.8/site-packages',\n",
       " '/mnt/c/Users/eid0112947/OneDrive - Eni/ENI/Projects/Prove/sci_ML/pdearena',\n",
       " '/mnt/c/Users/eid0112947/OneDrive - Eni/ENI/Projects/Prove/helper_functions',\n",
       " '/mnt/c/Users/eid0112947/OneDrive - Eni/Documenti/RESEARCH/pdearena/pdedatagen/..',\n",
       " '/tmp/tmpfo0jihb_']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hdf5_to_dict(file):\n",
    "    d = dict()\n",
    "    for key,val in file.items():\n",
    "        if type(val) == h5py._hl.dataset.Dataset:\n",
    "            d[key] = np.array(val)\n",
    "        else:\n",
    "            d[key] = hdf5_to_dict(val)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing buo_y\n",
      "processing dt\n",
      "processing dx\n",
      "processing dy\n",
      "processing t\n",
      "processing u\n",
      "processing vx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing vy\n",
      "processing x\n",
      "processing y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time per step: 0.39934s\n"
     ]
    }
   ],
   "source": [
    "source_folder = '../pdearena_data/NavierStokes-2D-64x64/'\n",
    "target_folder = '../pdearena_data/NavierStokes-2D-64x64-io_test/data/'\n",
    "\n",
    "touch_dir(target_folder)\n",
    "\n",
    "# seeds = [946191, 795933, 585798]\n",
    "n_keep= 1\n",
    "files_keep = [f for f in os.listdir(source_folder) if f.find('train')!=-1 & f.find('yaml')==-1][:n_keep]\n",
    "\n",
    "\n",
    "\n",
    "for file in tqdm(\n",
    "        files_keep, \n",
    "        total=len(files_keep), \n",
    "        miniters=len(files_keep)//5,\n",
    "        leave=False):\n",
    "    with h5py.File(os.path.join(source_folder,file), 'r') as hf_source:\n",
    "        here = 1\n",
    "        d = hdf5_to_dict(hf_source)\n",
    "        with h5py.File(os.path.join(target_folder,file), \"w\") as h5f_target:\n",
    "            # List all groups\n",
    "            # print(\"Keys: %s\" % h5f.keys())\n",
    "            mode = next(iter(d.keys()))\n",
    "            dataset = h5f_target.create_group(mode)\n",
    "            for k,v in d[mode].items():\n",
    "                print('processing {}'.format(k))\n",
    "                chunks = (100,)\n",
    "                if len(v.shape) > 1:\n",
    "                    for i in v.shape[1:]:  \n",
    "                        chunks=chunks+(i,)\n",
    "                dataset.create_dataset(\n",
    "                    k, \n",
    "                    data = v,\n",
    "                    shape = v.shape,\n",
    "                    # chunks = chunks\n",
    "                )\n",
    "\n",
    "file = target_folder +  files_keep[0]\n",
    "\n",
    "n_test = 10\n",
    "t1 = time()\n",
    "for _ in range(n_test):\n",
    "    read_h5_numpy(file)\n",
    "t2 = time() - t1\n",
    "print('time per step: {:0.5f}s'.format(t2/n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time per step: 0.37154s\n"
     ]
    }
   ],
   "source": [
    "# test h5py with other compressions\n",
    "\n",
    "source_folder = '../pdearena_data/NavierStokes-2D-64x64/'\n",
    "target_folder = '../pdearena_data/NavierStokes-2D-64x64-io_test/data/'\n",
    "\n",
    "touch_dir(target_folder)\n",
    "\n",
    "# seeds = [946191, 795933, 585798]\n",
    "n_keep= 1\n",
    "files_keep = [f for f in os.listdir(source_folder) if f.find('train')!=-1 & f.find('yaml')==-1][:n_keep]\n",
    "\n",
    "compressor = hdf5plugin.LZ4()\n",
    "file_save = files_keep[0][:-3] + '_lz4' + '.h5'\n",
    "\n",
    "# compressor = hdf5plugin.Blosc(cname='lz4', clevel = 1)\n",
    "# file_save = files_keep[0][:-3] + '_Blosc_lz4' + '.h5'\n",
    "\n",
    "# compressor = hdf5plugin.Blosc(cname='blosclz', clevel = 1)\n",
    "# file_save = files_keep[0][:-3] + '_Blosc_blosclz' + '.h5'\n",
    "\n",
    "# compressor = hdf5plugin.Blosc(cname='snappy', clevel = 1)\n",
    "# file_save = files_keep[0][:-3] + '_Blosc_snappy' + '.h5'\n",
    "\n",
    "# compressor = hdf5plugin.Blosc(cname='lz4', clevel = 1)\n",
    "# file_save = files_keep[0][:-3] + '_Blosc_lz4' + '.h5'\n",
    "\n",
    "compressor = hdf5plugin.Blosc(cname='zstd', clevel = 1)\n",
    "file_save = files_keep[0][:-3] + '_Blosc_zstd' + '.h5'\n",
    "\n",
    "# compressor = hdf5plugin.Blosc2(cname='lz4', clevel = 1)\n",
    "# file_save = files_keep[0][:-3] + '_Blosc2_lz4' + '.h5'\n",
    "\n",
    "# compressor = hdf5plugin.Blosc2(cname='zstd', clevel = 1)\n",
    "# file_save = files_keep[0][:-3] + '_Blosc2_zstd' + '.h5'\n",
    "\n",
    "# compressor = hdf5plugin.Blosc2(cname='blosclz', clevel = 1)\n",
    "# file_save = files_keep[0][:-3] + '_Blosc2_blosclz' + '.h5'\n",
    "\n",
    "# compressor = hdf5plugin.BZip2()\n",
    "# file_save = files_keep[0][:-3] + '_BZip2' + '.h5'\n",
    "\n",
    "os.path.join(target_folder,file_save)\n",
    "os.path.join(source_folder,file)\n",
    "\n",
    "\n",
    "for file in tqdm(\n",
    "        files_keep, \n",
    "        total=len(files_keep), \n",
    "        miniters=len(files_keep)//5,\n",
    "        leave=False):\n",
    "    with h5py.File(os.path.join(source_folder,file), 'r') as hf_source:\n",
    "        here = 1\n",
    "        d = hdf5_to_dict(hf_source)\n",
    "        with h5py.File(os.path.join(target_folder,file_save), \"w\") as h5f_target:\n",
    "            # List all groups\n",
    "            # print(\"Keys: %s\" % h5f.keys())\n",
    "            mode = next(iter(d.keys()))\n",
    "            dataset = h5f_target.create_group(mode)\n",
    "            for k,v in d[mode].items():\n",
    "                # print('processing {}'.format(k))\n",
    "                chunks = (100,)\n",
    "                if len(v.shape) > 1:\n",
    "                    for i in v.shape[1:]:  \n",
    "                        chunks=chunks+(i,)\n",
    "                dataset.create_dataset(\n",
    "                    k, \n",
    "                    data = v,\n",
    "                    shape = v.shape,\n",
    "                    **compressor\n",
    "                )\n",
    "\n",
    "file = target_folder +  files_keep[0]\n",
    "\n",
    "n_test = 10\n",
    "t1 = time()\n",
    "for _ in range(n_test):\n",
    "    read_h5_numpy(file)\n",
    "t2 = time() - t1\n",
    "print('time per step: {:0.5f}s'.format(t2/n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time per step: 0.31201s\n"
     ]
    }
   ],
   "source": [
    "# test pickle\n",
    "\n",
    "'''\n",
    "filehandler = open(b\"Fruits.obj\",\"wb\")\n",
    "pickle.dump(banana,filehandler)\n",
    "\n",
    "file = open(\"Fruits.obj\",'rb')\n",
    "object_file = pickle.load(file)\n",
    "'''\n",
    "\n",
    "# test h5py with other compressions\n",
    "import hdf5plugin\n",
    "\n",
    "source_folder = '../pdearena_data/NavierStokes-2D-64x64/'\n",
    "target_folder = '../pdearena_data/NavierStokes-2D-64x64-io_test/data/'\n",
    "\n",
    "touch_dir(target_folder)\n",
    "\n",
    "n_keep= 1\n",
    "files_keep = [f for f in os.listdir(source_folder) if f.find('train')!=-1 & f.find('yaml')==-1][:n_keep]\n",
    "\n",
    "file\n",
    "file_save = files_keep[0][:-3] + '.pkl'\n",
    "\n",
    "os.path.join(target_folder,file_save)\n",
    "os.path.join(source_folder,file)\n",
    "\n",
    "\n",
    "for file in tqdm(\n",
    "        files_keep, \n",
    "        total=len(files_keep), \n",
    "        miniters=len(files_keep)//5,\n",
    "        leave=False):\n",
    "    with h5py.File(os.path.join(source_folder,file), 'r') as hf_source:\n",
    "        here = 1\n",
    "        d = hdf5_to_dict(hf_source)\n",
    "        filehandler = open(os.path.join(target_folder,file_save),\"wb\")\n",
    "        cPickle.dump(d,filehandler,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "file = target_folder +  file_save\n",
    "file_save\n",
    "n_test = 10\n",
    "t1 = time()\n",
    "for _ in range(n_test):\n",
    "    filehandler = open(file,'rb')\n",
    "    object_file = cPickle.load(filehandler)\n",
    "t2 = time() - t1\n",
    "print('time per step: {:0.5f}s'.format(t2/n_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \r"
     ]
    }
   ],
   "source": [
    "# test parquet\n",
    "\n",
    "'''\n",
    "NOT WORKING\n",
    "'''\n",
    "# import pyarrow as pa\n",
    "# import pyarrow.parquet as pq\n",
    "\n",
    "# '''\n",
    "# data_dict = {\"name\": [\"Alice\"], \"age\": [30], \"city\": [\"New York\"]}\n",
    "# table = pa.Table.from_pydict(data_dict)\n",
    "# pq.write_table(table, 'data.parquet')\n",
    "# '''\n",
    "# source_folder = '../pdearena_data/NavierStokes-2D-64x64/'\n",
    "# target_folder = '../pdearena_data/NavierStokes-2D-64x64-io_test/data/'\n",
    "\n",
    "# touch_dir(target_folder)\n",
    "\n",
    "# n_keep= 1\n",
    "# files_keep = [f for f in os.listdir(source_folder) if f.find('train')!=-1 & f.find('yaml')==-1][:n_keep]\n",
    "\n",
    "# file\n",
    "# file_save = files_keep[0][:-3] + '.parquet'\n",
    "\n",
    "# os.path.join(target_folder,file_save)\n",
    "# os.path.join(source_folder,file)\n",
    "\n",
    "\n",
    "# for file in tqdm(\n",
    "#         files_keep, \n",
    "#         total=len(files_keep), \n",
    "#         miniters=len(files_keep)//5,\n",
    "#         leave=False):\n",
    "#     with h5py.File(os.path.join(source_folder,file), 'r') as hf_source:\n",
    "#         here = 1\n",
    "#         d = hdf5_to_dict(hf_source)\n",
    "#         table = pa.Table.from_pydict(d[next(iter(d.keys()))])\n",
    "#         pq.write_table(table, os.path.join(target_folder,file_save))\n",
    "\n",
    "\n",
    "# file = target_folder +  file_save\n",
    "# file_save\n",
    "# n_test = 10\n",
    "# t1 = time()\n",
    "# for _ in range(n_test):\n",
    "#     filehandler = open(file,'rb')\n",
    "#     object_file = cPickle.load(filehandler)\n",
    "# t2 = time() - t1\n",
    "# print('time per step: {:0.5f}s'.format(t2/n_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file NavierStokes2D_train_198010_0.50000_100.h5 - time per step: 0.59909s\n",
      "file NavierStokes2D_train_126288_0.50000_100.h5 - time per step: 0.33895s\n",
      "file NavierStokes2D_train_126288_0.50000_100.h5 - time per step: 0.34188s\n",
      "file NavierStokes2D_train_126288_0.50000_100.pkl - time per step: 0.31170s\n",
      "file NavierStokes2D_train_126288_0.50000_100_Blosc2_blosclz.h5 - time per step: 0.40147s\n",
      "file NavierStokes2D_train_126288_0.50000_100_Blosc2_lz4.h5 - time per step: 0.37916s\n",
      "file NavierStokes2D_train_126288_0.50000_100_Blosc2_zstd.h5 - time per step: 0.44810s\n",
      "file NavierStokes2D_train_126288_0.50000_100_Blosc_blosclz.h5 - time per step: 0.38021s\n",
      "file NavierStokes2D_train_126288_0.50000_100_Blosc_lz4.h5 - time per step: 0.37658s\n",
      "file NavierStokes2D_train_126288_0.50000_100_Blosc_snappy.h5 - time per step: 0.46755s\n",
      "file NavierStokes2D_train_126288_0.50000_100_Blosc_zstd.h5 - time per step: 0.48643s\n",
      "file NavierStokes2D_train_126288_0.50000_100_BZip2.h5 - time per step: 3.71461s\n",
      "file NavierStokes2D_train_126288_0.50000_100_lz4.h5 - time per step: 0.61339s\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "    '../pdearena_data/NavierStokes-2D-64x64-sample/data/NavierStokes2D_train_198010_0.50000_100.h5',\n",
    "    '../pdearena_data/NavierStokes-2D-64x64/NavierStokes2D_train_126288_0.50000_100.h5',\n",
    "    ] \n",
    "\n",
    "dir = '../pdearena_data/NavierStokes-2D-64x64-io_test/data/'\n",
    "files.extend([dir + f for f in os.listdir(dir)])\n",
    "\n",
    "n_test = 10\n",
    "for file in files:\n",
    "    t1 = time()\n",
    "    for _ in range(n_test):\n",
    "        if 'pkl' in file:\n",
    "            filehandler = open(file,'rb')\n",
    "            object_file = cPickle.load(filehandler)\n",
    "        else:\n",
    "            read_h5_numpy(file)\n",
    "    t2 = time() - t1\n",
    "    print('file {} - time per step: {:0.5f}s'.format(\n",
    "        file.split('/')[-1],\n",
    "        t2/n_test)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [01:41<00:00,  3.07it/s]\n",
      "100%|██████████| 312/312 [01:56<00:00,  2.67it/s]\n",
      "100%|██████████| 312/312 [14:30<00:00,  2.79s/it]  \n",
      "100%|██████████| 312/312 [01:19<00:00,  3.95it/s] \n"
     ]
    }
   ],
   "source": [
    "### Chosen the following saving strategies\n",
    "'''\n",
    "- hdf5plugin.Blosc(cname='lz4', clevel = 1)\n",
    "- pickle\n",
    "'''\n",
    "compressor = hdf5plugin.Blosc(cname='lz4', clevel = 1)\n",
    "\n",
    "input_folder = '../pdearena_data/NavierStokes-2D-64x64/'\n",
    "target_folders = [\n",
    "    '../pdearena_data/NavierStokes-2D-64x64_blosc_lz4/',\n",
    "    '../pdearena_data/NavierStokes-2D-64x64_pkl/',\n",
    "]\n",
    "files = os.listdir(input_folder)\n",
    "\n",
    "\n",
    "def convert_file(filein,fileout):\n",
    "    with h5py.File(filein, 'r') as hf_source:\n",
    "        d = hdf5_to_dict(hf_source)\n",
    "        if 'pkl' in fileout:\n",
    "            with open(fileout,\"wb\") as filehandler:\n",
    "                cPickle.dump(d,filehandler,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            # pass\n",
    "        else:\n",
    "            with h5py.File(fileout, \"w\") as h5f_target:\n",
    "                mode = next(iter(d.keys()))\n",
    "                dataset = h5f_target.create_group(mode)\n",
    "                for k,v in d[mode].items():\n",
    "                    # print('processing {}'.format(k))\n",
    "                    dataset.create_dataset(\n",
    "                        k, \n",
    "                        data = v,\n",
    "                        shape = v.shape,\n",
    "                        **compressor\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "for target_folder in target_folders:\n",
    "    touch_dir(target_folder)\n",
    "    \n",
    "    for file in tqdm(files,total=len(files)):\n",
    "        try:\n",
    "            if 'yaml' not in file:\n",
    "                fileout = file\n",
    "                if 'pkl' in target_folder:\n",
    "                    fileout = fileout[:-3] + '.pkl'\n",
    "                convert_file(\n",
    "                    os.path.join(input_folder,file),\n",
    "                    os.path.join(target_folder,fileout)\n",
    "                )\n",
    "            else:\n",
    "                fileout = file\n",
    "                shutil.copyfile(\n",
    "                    os.path.join(input_folder,file),\n",
    "                    os.path.join(target_folder,fileout)\n",
    "                )\n",
    "        except:\n",
    "            print(file,fileout)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'> <class 'NoneType'> <class 'NoneType'>\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'> <class 'NoneType'> <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "target_folders = '../pdearena_data/NavierStokes-2D-64x64_pkl/'\n",
    "files = os.listdir(target_folders)\n",
    "file = [x for x in files if 'valid' in x][0]\n",
    "file = os.path.join(target_folders,file)\n",
    "\n",
    "file = '/mnt/c/Users/eid0112947/OneDrive - Eni/Documenti/RESEARCH/pdearena/pdearena_data/NavierStokes-2D-64x64_pkl/NavierStokes2D_valid_61849_0.50000.pkl'\n",
    "with open(file,'rb') as filehandler: \n",
    "    object_file = cPickle.load(filehandler)\n",
    "\n",
    "data = object_file['valid']\n",
    "num = data[\"u\"].shape[0]\n",
    "\n",
    "iter_start = 0\n",
    "iter_end = num\n",
    "\n",
    "for idx in range(iter_start, iter_end):\n",
    "    u = torch.tensor(data[\"u\"][idx])\n",
    "    vx = torch.tensor(data[\"vx\"][idx])\n",
    "    vy = torch.tensor(data[\"vy\"][idx])\n",
    "    if \"buo_y\" in data and False:\n",
    "        cond = torch.tensor(data[\"buo_y\"][idx]).unsqueeze(0).float()\n",
    "    else:\n",
    "        cond = None\n",
    "\n",
    "    v = torch.cat((vx[:, None], vy[:, None]), dim=1)\n",
    "\n",
    "    if False:\n",
    "        gridx = torch.linspace(0, 1, data[\"x\"][idx].shape[0])\n",
    "        gridy = torch.linspace(0, 1, data[\"y\"][idx].shape[0])\n",
    "        gridx = gridx.reshape(1,gridx.size(0),1,).repeat(1,1,gridy.size(0))\n",
    "        gridy = gridy.reshape(1,1,gridy.size(0),).repeat(1,gridx.size(1),1,)\n",
    "        grid = torch.cat((gridx[:, None], gridy[:, None]), dim=1)\n",
    "    else:\n",
    "        grid = None\n",
    "    if idx >= 23:\n",
    "        print(\n",
    "            type(u.unsqueeze(1).float()), \n",
    "            type(v.float()), \n",
    "            type(cond), \n",
    "            type(grid)\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdearena",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
